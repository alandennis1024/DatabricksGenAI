{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0ce49a",
   "metadata": {},
   "source": [
    "# Chapter 13 - Step 0: Generate Demo Data\n",
    "\n",
    "This notebook corresponds to the data generation step for the Data Quality Agent demo.\n",
    "It demonstrates:\n",
    "\n",
    "1. Creating a `sales_transactions` table with synthetic data\n",
    "2. Injecting a small percentage of data quality issues\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run this notebook in a Databricks workspace\n",
    "- Access to a Unity Catalog catalog and schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa70aa",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the catalog and schema where the demo table will live.\n",
    "Change these to match your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ada9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = \"demo\"\n",
    "SCHEMA  = \"finance\"\n",
    "TABLE   = \"sales_transactions\"\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
    "\n",
    "print(f\"Using {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2a397",
   "metadata": {},
   "source": [
    "## Step 1 - Create the sales_transactions table with synthetic data\n",
    "\n",
    "The table is designed to give the agent interesting columns to reason about:\n",
    "numeric ranges, date ordering, email formats, enum values, and cross-column\n",
    "relationships. A small percentage of rows intentionally contain data quality\n",
    "issues so the agent has real violations to detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType,\n",
    "    DoubleType, DateType\n",
    ")\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "\n",
    "NUM_ROWS = 2000\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "start_date = date(2024, 1, 1)\n",
    "statuses = [\"completed\", \"pending\", \"cancelled\", \"refunded\"]\n",
    "payment_methods = [\"credit_card\", \"debit_card\", \"wire_transfer\", \"paypal\"]\n",
    "domains = [\"example.com\", \"testmail.org\", \"acme.co\", \"bigcorp.net\"]\n",
    "\n",
    "def random_email(i):\n",
    "    return f\"customer_{i}@{random.choice(domains)}\"\n",
    "\n",
    "def random_date_pair():\n",
    "    \"\"\"Return an (order_date, ship_date) pair where ship >= order most of the time.\"\"\"\n",
    "    order = start_date + timedelta(days=random.randint(0, 365))\n",
    "    # ~5% of rows intentionally have ship_date before order_date\n",
    "    if random.random() < 0.05:\n",
    "        ship = order - timedelta(days=random.randint(1, 5))\n",
    "    else:\n",
    "        ship = order + timedelta(days=random.randint(0, 14))\n",
    "    return order, ship\n",
    "\n",
    "rows = []\n",
    "for i in range(1, NUM_ROWS + 1):\n",
    "    original_price = round(random.uniform(5.0, 500.0), 2)\n",
    "    # ~3% of rows have discount > original (data quality issue)\n",
    "    if random.random() < 0.03:\n",
    "        discount_price = round(original_price + random.uniform(1, 50), 2)\n",
    "    else:\n",
    "        discount_price = round(original_price * random.uniform(0.5, 1.0), 2)\n",
    "\n",
    "    quantity = random.randint(1, 200)\n",
    "    # ~2% negative quantities (data quality issue)\n",
    "    if random.random() < 0.02:\n",
    "        quantity = -random.randint(1, 10)\n",
    "\n",
    "    order_dt, ship_dt = random_date_pair()\n",
    "\n",
    "    rows.append((\n",
    "        f\"TXN-{i:06d}\",\n",
    "        random_email(i),\n",
    "        round(original_price * quantity, 2),\n",
    "        original_price,\n",
    "        discount_price,\n",
    "        quantity,\n",
    "        order_dt,\n",
    "        ship_dt,\n",
    "        random.choice(statuses),\n",
    "        random.choice(payment_methods),\n",
    "    ))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"transaction_id\",  StringType(),  False),\n",
    "    StructField(\"customer_email\",  StringType(),  True),\n",
    "    StructField(\"amount\",          DoubleType(),  True),\n",
    "    StructField(\"original_price\",  DoubleType(),  True),\n",
    "    StructField(\"discount_price\",  DoubleType(),  True),\n",
    "    StructField(\"quantity\",        IntegerType(), True),\n",
    "    StructField(\"order_date\",      DateType(),    True),\n",
    "    StructField(\"ship_date\",       DateType(),    True),\n",
    "    StructField(\"status\",          StringType(),  True),\n",
    "    StructField(\"payment_method\",  StringType(),  True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(rows, schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(TABLE)\n",
    "\n",
    "print(f\"Created {CATALOG}.{SCHEMA}.{TABLE} with {df.count()} rows\")\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf77de",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Continue with **01_create_table_and_log_model.py** to log the model and\n",
    "generate data quality rules."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
