# Data Quality Agent with MLflow

## Purpose
This project provides an MLflow model agent that accepts a pandas DataFrame and proposes data quality rules using a Large Language Model (LLM). The agent analyzes the DataFrame's schema, column names, and sample data, then generates rules in YAML format to help ensure data quality.

## How It Works
- The agent receives a DataFrame as input.
- It extracts the schema, column names, and a sample of the data.
- It builds a prompt and sends it to an LLM (currently a dummy client; replace with your LLM API).
- The LLM returns data quality rules in YAML format.
- The agent outputs these rules for use in data validation or documentation.

## Usage
1. Load the MLflow model agent (see `data_quality_agent.py`).
2. Pass a pandas DataFrame to the agent's `propose_rules` method or use MLflow's `predict` interface.
3. Receive YAML-formatted data quality rules.

## Customization
- Replace `DummyLLMClient` in `data_quality_agent.py` with your preferred LLM API client (e.g., OpenAI, Azure OpenAI, local LLM).
- Adjust the prompt template as needed for your use case.

## Example Output
```yaml
rules:
  - column: passenger_count
    rule: must be >= 1
  - column: fare_amount
    rule: must be > 0
```

## Files
- `src/data_quality_agent/data_quality_agent.py`: Main agent and MLflow wrapper implementation.
- `README.md`: This documentation.

## Next Steps
- Integrate with your LLM provider.
- Extend rule generation logic for more advanced data quality checks.
- Add tests and examples.

---

# data_quality_agent

The 'data_quality_agent' project was generated by using the default-python template.

* `src/`: Python source code for this project.
  * `src/data_quality_agent/`: Shared Python code that can be used by jobs and pipelines.
* `resources/`:  Resource configurations (jobs, pipelines, etc.)
* `tests/`: Unit tests for the shared Python code.
* `fixtures/`: Fixtures for data sets (primarily used for testing).


## Getting started

Choose how you want to work on this project:

(a) Directly in your Databricks workspace, see
    https://docs.databricks.com/dev-tools/bundles/workspace.

(b) Locally with an IDE like Cursor or VS Code, see
    https://docs.databricks.com/dev-tools/vscode-ext.html.

(c) With command line tools, see https://docs.databricks.com/dev-tools/cli/databricks-cli.html

If you're developing with an IDE, dependencies for this project should be installed using uv:

*  Make sure you have the UV package manager installed.
   It's an alternative to tools like pip: https://docs.astral.sh/uv/getting-started/installation/.
*  Run `uv sync --dev` to install the project's dependencies.


# Using this project using the CLI

The Databricks workspace and IDE extensions provide a graphical interface for working
with this project. It's also possible to interact with it directly using the CLI:

1. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks configure
    ```

2. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] data_quality_agent_job` to your workspace.
    You can find that resource by opening your workpace and clicking on **Jobs & Pipelines**.

3. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```
   Note that the default job from the template has a schedule that runs every day
   (defined in resources/sample_job.job.yml). The schedule
   is paused when deploying in development mode (see
   https://docs.databricks.com/dev-tools/bundles/deployment-modes.html).

4. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```

5. Finally, to run tests locally, use `pytest`:
   ```
   $ uv run pytest
   ```
